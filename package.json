{
  "name": "code-quality-benchmark",
  "version": "1.0.0",
  "type": "module",
  "description": "A TypeScript library for evaluating AI coding agents on code quality",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "scripts": {
    "build": "tsc",
    "check": "tsc --noEmit --pretty",
    "check:all": "npm run check && biome check .",
    "lint": "biome lint src/",
    "format": "biome format --write .",
    "dev": "tsc --watch",
    "benchmark": "npm run build && node dist/benchmark-runner.js",
    "benchmark:existing": "npm run build && node dist/benchmark-runner-existing.js",
    "benchmark:test-functionality": "npm run build && node dist/benchmark-test-functionality.js",
    "check:command-refs": "claude -p 'Check that the error messages and comments and docs re the commands (eg npm run benchmark:test-functionality), eg in src/benchmark-runner.ts src/benchmark-runner-existing.ts src/benchmark-test-functionality.ts README.md, are in sync with what is actually the case (see package.json)'",
    "clean": "rm -rf dist"
  },
  "keywords": [
    "ai",
    "code-quality",
    "benchmark",
    "claude",
    "evaluation"
  ],
  "author": "",
  "license": "MIT",
  "dependencies": {
    "@anthropic-ai/claude-code": "^1.0.0",
    "@types/fs-extra": "^11.0.4",
    "@types/tmp": "^0.2.6",
    "cmd-ts": "^0.14.1",
    "dedent": "^1.7.0",
    "detect-port": "^2.1.0",
    "execa": "^9.6.0",
    "fs-extra": "^11.3.1",
    "p-limit": "^7.1.1",
    "pino": "^9.9.0",
    "pino-pretty": "^13.1.1",
    "tmp": "^0.2.5",
    "ts-pattern": "^5.8.0",
    "ts-unimplemented": "^2.0.0",
    "zod": "^4.1.5"
  },
  "devDependencies": {
    "@biomejs/biome": "2.2.3",
    "@types/node": "^20.10.0",
    "typescript": "^5.9.2"
  }
}
